2021-06-26 14:22:43,972 - run.py[line:49] - INFO: exp params
2021-06-26 14:22:43,972 - run.py[line:51] - INFO: device: cuda:3
2021-06-26 14:22:43,972 - run.py[line:51] - INFO: model: bert_mean_pool
2021-06-26 14:22:43,972 - run.py[line:51] - INFO: dataset: CHIP-STS
2021-06-26 14:22:43,972 - run.py[line:51] - INFO: data_method: CHIP-STS_pos_only
2021-06-26 14:22:43,972 - run.py[line:51] - INFO: train_method: cons
2021-06-26 14:22:43,972 - run.py[line:51] - INFO: eval_method: auc
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: bert_path: /home/users/liuhongli/Models/prev_trained_model/roberta_wwm_large_ext
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: log_name: CHIP_STS_ROBERTA_WWM_LARGE_AUC
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: save_path: /home/users/liuhongli/Models/prev_trained_model/roberta_wwm_large_sts_auc/
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: dev_step: 10
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: dev_rate: 1.0
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: test_step: 1000
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: require_improvement: 1000
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: num_epochs: 3
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: batch_size: 96
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: pad_size: 32
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: hidden_size: 768
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: hitn: 10
2021-06-26 14:22:43,973 - run.py[line:51] - INFO: output_size: 100
2021-06-26 14:22:43,974 - run.py[line:51] - INFO: learning_rate: 2e-05
2021-06-26 14:22:43,974 - run.py[line:51] - INFO: margin: 0.1
2021-06-26 14:22:43,974 - run.py[line:51] - INFO: gama: 0.1
2021-06-26 14:22:43,974 - run.py[line:51] - INFO: seed: 1
2021-06-26 14:22:43,974 - run.py[line:70] - INFO: Loading data...
2021-06-26 14:22:56,356 - run.py[line:80] - INFO: Time usage:0:00:12
2021-06-26 14:28:40,202 - run.py[line:49] - INFO: exp params
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: device: cuda:3
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: model: bert_mean_pool
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: dataset: CHIP-STS
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: data_method: CHIP-STS_pos_only
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: train_method: cons
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: eval_method: auc
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: bert_path: /home/users/liuhongli/Models/prev_trained_model/roBerta-wwm-ext-large-chinese/
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: log_name: CHIP_STS_ROBERTA_WWM_LARGE_AUC
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: save_path: /home/users/liuhongli/Models/prev_trained_model/roberta_wwm_large_sts_auc/
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: dev_step: 10
2021-06-26 14:28:40,203 - run.py[line:51] - INFO: dev_rate: 1.0
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: test_step: 1000
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: require_improvement: 1000
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: num_epochs: 3
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: batch_size: 96
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: pad_size: 32
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: hidden_size: 768
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: hitn: 10
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: output_size: 100
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: learning_rate: 2e-05
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: margin: 0.1
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: gama: 0.1
2021-06-26 14:28:40,204 - run.py[line:51] - INFO: seed: 1
2021-06-26 14:28:40,205 - run.py[line:70] - INFO: Loading data...
2021-06-26 14:28:50,977 - run.py[line:80] - INFO: Time usage:0:00:11
2021-06-26 14:29:01,327 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:77] - INFO: Epoch [1/3]
2021-06-26 14:29:15,747 - run.py[line:49] - INFO: exp params
2021-06-26 14:29:15,747 - run.py[line:51] - INFO: device: cuda:3
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: model: bert_mean_pool
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: dataset: CHIP-STS
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: data_method: CHIP-STS_pos_only
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: train_method: cons
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: eval_method: auc
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: bert_path: /home/users/liuhongli/Models/prev_trained_model/roBerta-wwm-ext-large-chinese/
2021-06-26 14:29:15,748 - run.py[line:51] - INFO: log_name: CHIP_STS_ROBERTA_WWM_LARGE_AUC
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: save_path: /home/users/liuhongli/Models/prev_trained_model/roberta_wwm_large_sts_auc/
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: dev_step: 10
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: dev_rate: 1.0
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: test_step: 1000
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: require_improvement: 1000
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: num_epochs: 3
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: batch_size: 48
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: pad_size: 32
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: hidden_size: 768
2021-06-26 14:29:15,749 - run.py[line:51] - INFO: hitn: 10
2021-06-26 14:29:15,750 - run.py[line:51] - INFO: output_size: 100
2021-06-26 14:29:15,750 - run.py[line:51] - INFO: learning_rate: 1e-05
2021-06-26 14:29:15,750 - run.py[line:51] - INFO: margin: 0.1
2021-06-26 14:29:15,750 - run.py[line:51] - INFO: gama: 0.1
2021-06-26 14:29:15,750 - run.py[line:51] - INFO: seed: 1
2021-06-26 14:29:15,751 - run.py[line:70] - INFO: Loading data...
2021-06-26 14:29:26,681 - run.py[line:80] - INFO: Time usage:0:00:11
2021-06-26 14:29:38,082 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:77] - INFO: Epoch [1/3]
2021-06-26 14:29:59,192 - run.py[line:49] - INFO: exp params
2021-06-26 14:29:59,192 - run.py[line:51] - INFO: device: cuda:3
2021-06-26 14:29:59,193 - run.py[line:51] - INFO: model: bert_mean_pool
2021-06-26 14:29:59,193 - run.py[line:51] - INFO: dataset: CHIP-STS
2021-06-26 14:29:59,193 - run.py[line:51] - INFO: data_method: CHIP-STS_pos_only
2021-06-26 14:29:59,193 - run.py[line:51] - INFO: train_method: cons
2021-06-26 14:29:59,193 - run.py[line:51] - INFO: eval_method: auc
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: bert_path: /home/users/liuhongli/Models/prev_trained_model/roBerta-wwm-ext-large-chinese/
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: log_name: CHIP_STS_ROBERTA_WWM_LARGE_AUC
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: save_path: /home/users/liuhongli/Models/prev_trained_model/roberta_wwm_large_sts_auc/
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: dev_step: 10
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: dev_rate: 1.0
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: test_step: 1000
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: require_improvement: 1000
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: num_epochs: 3
2021-06-26 14:29:59,194 - run.py[line:51] - INFO: batch_size: 32
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: pad_size: 32
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: hidden_size: 768
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: hitn: 10
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: output_size: 100
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: learning_rate: 1e-05
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: margin: 0.1
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: gama: 0.1
2021-06-26 14:29:59,195 - run.py[line:51] - INFO: seed: 1
2021-06-26 14:29:59,196 - run.py[line:70] - INFO: Loading data...
2021-06-26 14:30:10,225 - run.py[line:80] - INFO: Time usage:0:00:11
2021-06-26 14:30:21,738 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:77] - INFO: Epoch [1/3]
2021-06-26 14:30:37,499 - run.py[line:49] - INFO: exp params
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: device: cuda:3
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: model: bert_mean_pool
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: dataset: CHIP-STS
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: data_method: CHIP-STS_pos_only
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: train_method: cons
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: eval_method: auc
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: bert_path: /home/users/liuhongli/Models/prev_trained_model/roBerta-wwm-ext-large-chinese/
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: log_name: CHIP_STS_ROBERTA_WWM_LARGE_AUC
2021-06-26 14:30:37,499 - run.py[line:51] - INFO: save_path: /home/users/liuhongli/Models/prev_trained_model/roberta_wwm_large_sts_auc/
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: dev_step: 10
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: dev_rate: 1.0
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: test_step: 1000
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: require_improvement: 1000
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: num_epochs: 3
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: batch_size: 16
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: pad_size: 32
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: hidden_size: 768
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: hitn: 10
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: output_size: 100
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: learning_rate: 1e-05
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: margin: 0.1
2021-06-26 14:30:37,500 - run.py[line:51] - INFO: gama: 0.1
2021-06-26 14:30:37,501 - run.py[line:51] - INFO: seed: 1
2021-06-26 14:30:37,501 - run.py[line:70] - INFO: Loading data...
2021-06-26 14:30:49,450 - run.py[line:80] - INFO: Time usage:0:00:12
2021-06-26 14:31:00,581 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:77] - INFO: Epoch [1/3]
2021-06-26 14:31:36,382 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 10,  Train Loss: 1.877026081085205,  Val Acc: 0.8011676103202121, Val score: 0.8011676103202121, Time: 0:00:36 *
2021-06-26 14:32:18,579 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 20,  Train Loss: 0.4830837547779083,  Val Acc: 0.8357652818997773, Val score: 0.8357652818997773, Time: 0:01:18 *
2021-06-26 14:33:00,998 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 30,  Train Loss: 0.14201578497886658,  Val Acc: 0.8427833691969182, Val score: 0.8427833691969182, Time: 0:02:00 *
2021-06-26 14:33:43,538 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 40,  Train Loss: 0.28469762206077576,  Val Acc: 0.8559717681459864, Val score: 0.8559717681459864, Time: 0:02:43 *
2021-06-26 14:34:25,840 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 50,  Train Loss: 0.31546899676322937,  Val Acc: 0.8583807160166594, Val score: 0.8583807160166594, Time: 0:03:25 *
2021-06-26 14:35:08,435 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 60,  Train Loss: 0.24941633641719818,  Val Acc: 0.859694505758799, Val score: 0.859694505758799, Time: 0:04:08 *
2021-06-26 14:35:43,951 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 70,  Train Loss: 0.2882857024669647,  Val Acc: 0.8551036168844107, Val score: 0.8551036168844107, Time: 0:04:43 
2021-06-26 14:36:19,821 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 80,  Train Loss: 0.258987694978714,  Val Acc: 0.8563874057190229, Val score: 0.8563874057190229, Time: 0:05:19 
2021-06-26 14:37:02,915 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 90,  Train Loss: 0.21104465425014496,  Val Acc: 0.8674054890160426, Val score: 0.8674054890160426, Time: 0:06:02 *
2021-06-26 14:37:38,440 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 100,  Train Loss: 0.20701847970485687,  Val Acc: 0.8649879158844554, Val score: 0.8649879158844554, Time: 0:06:38 
2021-06-26 14:38:14,121 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 110,  Train Loss: 0.24901418387889862,  Val Acc: 0.8660326974890991, Val score: 0.8660326974890991, Time: 0:07:14 
2021-06-26 14:38:50,291 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 120,  Train Loss: 0.15228118002414703,  Val Acc: 0.865773689654112, Val score: 0.865773689654112, Time: 0:07:50 
2021-06-26 14:39:33,529 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 130,  Train Loss: 0.31633153557777405,  Val Acc: 0.8688594079970919, Val score: 0.8688594079970919, Time: 0:08:33 *
2021-06-26 14:40:15,915 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 140,  Train Loss: 0.31869029998779297,  Val Acc: 0.8692002933088725, Val score: 0.8692002933088725, Time: 0:09:15 *
2021-06-26 14:40:58,495 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 150,  Train Loss: 0.15083229541778564,  Val Acc: 0.8726931489677563, Val score: 0.8726931489677563, Time: 0:09:58 *
2021-06-26 14:41:40,935 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 160,  Train Loss: 0.06809240579605103,  Val Acc: 0.8795328558688901, Val score: 0.8795328558688901, Time: 0:10:40 *
2021-06-26 14:42:23,423 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 170,  Train Loss: 0.09443497657775879,  Val Acc: 0.8841302449399093, Val score: 0.8841302449399093, Time: 0:11:23 *
2021-06-26 14:42:58,793 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 180,  Train Loss: 0.3259055018424988,  Val Acc: 0.8839624898653183, Val score: 0.8839624898653183, Time: 0:11:58 
2021-06-26 14:43:34,723 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 190,  Train Loss: 0.07052762061357498,  Val Acc: 0.878976089026693, Val score: 0.878976089026693, Time: 0:12:34 
2021-06-26 14:44:10,033 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 200,  Train Loss: 0.22969186305999756,  Val Acc: 0.8777584271924226, Val score: 0.8777584271924226, Time: 0:13:09 
2021-06-26 14:44:45,495 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 210,  Train Loss: 0.04940303415060043,  Val Acc: 0.8778605552817973, Val score: 0.8778605552817973, Time: 0:13:45 
2021-06-26 14:45:21,326 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 220,  Train Loss: 0.06150306016206741,  Val Acc: 0.8778399296578722, Val score: 0.8778399296578722, Time: 0:14:21 
2021-06-26 14:45:56,700 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 230,  Train Loss: 0.07906486839056015,  Val Acc: 0.8788395848974432, Val score: 0.8788395848974432, Time: 0:14:56 
2021-06-26 14:46:32,101 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 240,  Train Loss: 0.0975787490606308,  Val Acc: 0.8772317862615343, Val score: 0.8772317862615343, Time: 0:15:32 
2021-06-26 14:47:07,485 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 250,  Train Loss: 0.016275113448500633,  Val Acc: 0.877352039899207, Val score: 0.877352039899207, Time: 0:16:07 
2021-06-26 14:47:42,811 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 260,  Train Loss: 0.24032987654209137,  Val Acc: 0.8776502989215424, Val score: 0.8776502989215424, Time: 0:16:42 
2021-06-26 14:48:18,028 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 270,  Train Loss: 0.2461106926202774,  Val Acc: 0.87969411074685, Val score: 0.87969411074685, Time: 0:17:17 
2021-06-26 14:48:53,372 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 280,  Train Loss: 0.12847162783145905,  Val Acc: 0.8776062975905021, Val score: 0.8776062975905021, Time: 0:17:53 
2021-06-26 14:49:28,996 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 290,  Train Loss: 0.06744127720594406,  Val Acc: 0.8758351190123501, Val score: 0.8758351190123501, Time: 0:18:28 
2021-06-26 14:50:04,430 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 300,  Train Loss: 0.11396663635969162,  Val Acc: 0.8770161547386809, Val score: 0.8770161547386809, Time: 0:19:04 
2021-06-26 14:50:40,060 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 310,  Train Loss: 0.12236250191926956,  Val Acc: 0.8770166547538063, Val score: 0.8770166547538063, Time: 0:19:39 
2021-06-26 14:51:15,511 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 320,  Train Loss: 0.2548972964286804,  Val Acc: 0.8790288406224288, Val score: 0.8790288406224288, Time: 0:20:15 
2021-06-26 14:51:50,707 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 330,  Train Loss: 0.24046681821346283,  Val Acc: 0.8828414559540425, Val score: 0.8828414559540425, Time: 0:20:50 
2021-06-26 14:52:33,239 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 340,  Train Loss: 0.1507483720779419,  Val Acc: 0.8850170217649084, Val score: 0.8850170217649084, Time: 0:21:33 *
2021-06-26 14:53:15,175 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 350,  Train Loss: 0.5454928874969482,  Val Acc: 0.8872755900866002, Val score: 0.8872755900866002, Time: 0:22:15 *
2021-06-26 14:53:56,999 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 360,  Train Loss: 0.07903791964054108,  Val Acc: 0.8896041605258559, Val score: 0.8896041605258559, Time: 0:22:56 *
2021-06-26 14:54:38,926 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 370,  Train Loss: 0.21104177832603455,  Val Acc: 0.8916682229637446, Val score: 0.8916682229637446, Time: 0:23:38 *
2021-06-26 14:55:20,812 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 380,  Train Loss: 0.0411873459815979,  Val Acc: 0.8925875007718985, Val score: 0.8925875007718985, Time: 0:24:20 *
2021-06-26 14:55:56,224 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 390,  Train Loss: 0.012944759801030159,  Val Acc: 0.8914369659682205, Val score: 0.8914369659682205, Time: 0:24:56 
2021-06-26 14:56:31,932 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 400,  Train Loss: 0.037392690777778625,  Val Acc: 0.8911742080197926, Val score: 0.8911742080197926, Time: 0:25:31 
2021-06-26 14:57:07,228 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 410,  Train Loss: 0.062144678086042404,  Val Acc: 0.8914824673446371, Val score: 0.8914824673446371, Time: 0:26:07 
2021-06-26 14:57:42,519 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 420,  Train Loss: 0.056253109127283096,  Val Acc: 0.8908496982033705, Val score: 0.8908496982033705, Time: 0:26:42 
2021-06-26 14:58:17,695 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 430,  Train Loss: 0.03265013545751572,  Val Acc: 0.8909605765574409, Val score: 0.8909605765574409, Time: 0:27:17 
2021-06-26 14:58:53,192 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 440,  Train Loss: 0.17800886929035187,  Val Acc: 0.8914017149018758, Val score: 0.8914017149018758, Time: 0:27:53 
2021-06-26 14:59:28,469 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 450,  Train Loss: 0.04760920628905296,  Val Acc: 0.890212428925975, Val score: 0.890212428925975, Time: 0:28:28 
2021-06-26 15:00:03,537 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 460,  Train Loss: 0.17251798510551453,  Val Acc: 0.891265210772626, Val score: 0.891265210772626, Time: 0:29:03 
2021-06-26 15:00:38,959 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 470,  Train Loss: 0.04893219470977783,  Val Acc: 0.8916872235385119, Val score: 0.8916872235385119, Time: 0:29:38 
2021-06-26 15:01:20,790 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 480,  Train Loss: 0.1521715223789215,  Val Acc: 0.8926075013769166, Val score: 0.8926075013769166, Time: 0:30:20 *
2021-06-26 15:02:02,658 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 490,  Train Loss: 0.2644822895526886,  Val Acc: 0.8946038117653057, Val score: 0.8946038117653057, Time: 0:31:02 *
2021-06-26 15:02:44,610 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 500,  Train Loss: 0.017641767859458923,  Val Acc: 0.8971688893589032, Val score: 0.8971688893589032, Time: 0:31:44 *
2021-06-26 15:02:45,139 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:77] - INFO: Epoch [2/3]
2021-06-26 15:03:26,461 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 510,  Train Loss: 0.16135472059249878,  Val Acc: 0.8981816699955172, Val score: 0.8981816699955172, Time: 0:32:26 *
2021-06-26 15:04:08,244 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 520,  Train Loss: 0.04464660584926605,  Val Acc: 0.8983099238751973, Val score: 0.8983099238751973, Time: 0:33:08 *
2021-06-26 15:04:43,373 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 530,  Train Loss: 0.09833575040102005,  Val Acc: 0.8979711636276997, Val score: 0.8979711636276997, Time: 0:33:43 
2021-06-26 15:05:19,004 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 540,  Train Loss: 0.03553709760308266,  Val Acc: 0.8972123906748181, Val score: 0.8972123906748181, Time: 0:34:18 
2021-06-26 15:05:54,560 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 550,  Train Loss: 0.10051588714122772,  Val Acc: 0.8970390104300656, Val score: 0.8970390104300656, Time: 0:34:54 
2021-06-26 15:06:30,178 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 560,  Train Loss: 0.15606485307216644,  Val Acc: 0.8965891218209351, Val score: 0.8965891218209351, Time: 0:35:30 
2021-06-26 15:07:05,261 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 570,  Train Loss: 0.03996709734201431,  Val Acc: 0.896160608858418, Val score: 0.896160608858418, Time: 0:36:05 
2021-06-26 15:07:40,348 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 580,  Train Loss: 0.1350310742855072,  Val Acc: 0.8961098573231839, Val score: 0.8961098573231839, Time: 0:36:40 
2021-06-26 15:08:15,837 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 590,  Train Loss: 0.15626578032970428,  Val Acc: 0.8964968690302881, Val score: 0.8964968690302881, Time: 0:37:15 
2021-06-26 15:08:51,418 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 600,  Train Loss: 0.022341500967741013,  Val Acc: 0.8962146104919675, Val score: 0.8962146104919675, Time: 0:37:51 
2021-06-26 15:09:26,784 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 610,  Train Loss: 0.037960439920425415,  Val Acc: 0.8965661211251641, Val score: 0.8965661211251641, Time: 0:38:26 
2021-06-26 15:10:01,878 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 620,  Train Loss: 0.03332669660449028,  Val Acc: 0.8968991311987189, Val score: 0.8968991311987189, Time: 0:39:01 
2021-06-26 15:10:37,381 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 630,  Train Loss: 0.08875610679388046,  Val Acc: 0.8972351413630262, Val score: 0.8972351413630262, Time: 0:39:37 
2021-06-26 15:11:12,603 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 640,  Train Loss: 0.14033497869968414,  Val Acc: 0.8976921551876944, Val score: 0.8976921551876944, Time: 0:40:12 
2021-06-26 15:11:47,940 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 650,  Train Loss: 0.09913520514965057,  Val Acc: 0.8978105337686465, Val score: 0.8978105337686465, Time: 0:40:47 
2021-06-26 15:12:23,280 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 660,  Train Loss: 0.06320347636938095,  Val Acc: 0.8983011736105018, Val score: 0.8983011736105018, Time: 0:41:23 
2021-06-26 15:13:05,788 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 670,  Train Loss: 0.10692374408245087,  Val Acc: 0.8988385648665872, Val score: 0.8988385648665872, Time: 0:42:05 *
2021-06-26 15:13:47,413 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 680,  Train Loss: 0.1280580461025238,  Val Acc: 0.8993543304684968, Val score: 0.8993543304684968, Time: 0:42:47 *
2021-06-26 15:14:22,486 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 690,  Train Loss: 0.009752493351697922,  Val Acc: 0.8991381989305175, Val score: 0.8991381989305175, Time: 0:43:22 
2021-06-26 15:14:57,562 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 700,  Train Loss: 0.15881100296974182,  Val Acc: 0.8989826942265005, Val score: 0.8989826942265005, Time: 0:43:57 
2021-06-26 15:15:32,607 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 710,  Train Loss: 0.04654904082417488,  Val Acc: 0.8986651846218348, Val score: 0.8986651846218348, Time: 0:44:32 
2021-06-26 15:16:07,950 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 720,  Train Loss: 0.034042954444885254,  Val Acc: 0.8981752948026679, Val score: 0.8981752948026679, Time: 0:45:07 
2021-06-26 15:16:43,203 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 730,  Train Loss: 0.08028578758239746,  Val Acc: 0.8979102867861752, Val score: 0.8979102867861752, Time: 0:45:43 
2021-06-26 15:17:18,379 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 740,  Train Loss: 0.025771597400307655,  Val Acc: 0.8973113936696585, Val score: 0.8973113936696585, Time: 0:46:18 
2021-06-26 15:17:53,576 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 750,  Train Loss: 0.015866044908761978,  Val Acc: 0.8973758956208425, Val score: 0.8973758956208425, Time: 0:46:53 
2021-06-26 15:18:28,888 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 760,  Train Loss: 0.03916976600885391,  Val Acc: 0.8973913960897317, Val score: 0.8973913960897317, Time: 0:47:28 
2021-06-26 15:19:04,032 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 770,  Train Loss: 0.025891540572047234,  Val Acc: 0.896999384231373, Val score: 0.896999384231373, Time: 0:48:03 
2021-06-26 15:19:39,395 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 780,  Train Loss: 0.014100179076194763,  Val Acc: 0.8968798806163887, Val score: 0.8968798806163887, Time: 0:48:39 
2021-06-26 15:20:14,696 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 790,  Train Loss: 0.10403342545032501,  Val Acc: 0.8967803776064226, Val score: 0.8967803776064226, Time: 0:49:14 
2021-06-26 15:20:49,885 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 800,  Train Loss: 0.07474873960018158,  Val Acc: 0.8970348853052805, Val score: 0.8970348853052805, Time: 0:49:49 
2021-06-26 15:21:25,193 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 810,  Train Loss: 0.015172584913671017,  Val Acc: 0.8965813715864905, Val score: 0.8965813715864905, Time: 0:50:25 
2021-06-26 15:22:00,416 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 820,  Train Loss: 0.09318385273218155,  Val Acc: 0.8964436174194269, Val score: 0.8964436174194269, Time: 0:51:00 
2021-06-26 15:22:35,378 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 830,  Train Loss: 0.059658896178007126,  Val Acc: 0.8964423673816133, Val score: 0.8964423673816133, Time: 0:51:35 
2021-06-26 15:23:10,678 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 840,  Train Loss: 0.010468215681612492,  Val Acc: 0.8969766335431647, Val score: 0.8969766335431647, Time: 0:52:10 
2021-06-26 15:23:45,925 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 850,  Train Loss: 0.029981620609760284,  Val Acc: 0.8977659074186994, Val score: 0.8977659074186994, Time: 0:52:45 
2021-06-26 15:24:20,988 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 860,  Train Loss: 0.009497256949543953,  Val Acc: 0.8983991765750914, Val score: 0.8983991765750914, Time: 0:53:20 
2021-06-26 15:24:56,274 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 870,  Train Loss: 0.10356166958808899,  Val Acc: 0.8985619314984279, Val score: 0.8985619314984279, Time: 0:53:56 
2021-06-26 15:25:31,321 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 880,  Train Loss: 0.03695325925946236,  Val Acc: 0.8987826881763173, Val score: 0.8987826881763173, Time: 0:54:31 
2021-06-26 15:26:06,788 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 890,  Train Loss: 0.022239763289690018,  Val Acc: 0.8991009478036711, Val score: 0.8991009478036711, Time: 0:55:06 
2021-06-26 15:26:41,918 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 900,  Train Loss: 0.08120353519916534,  Val Acc: 0.8993047039672951, Val score: 0.8993047039672951, Time: 0:55:41 
2021-06-26 15:27:23,964 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 910,  Train Loss: 0.06633178889751434,  Val Acc: 0.8995609617190921, Val score: 0.8995609617190921, Time: 0:56:23 *
2021-06-26 15:28:05,896 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 920,  Train Loss: 0.01756281778216362,  Val Acc: 0.8996899656214601, Val score: 0.8996899656214601, Time: 0:57:05 *
2021-06-26 15:28:47,814 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 930,  Train Loss: 0.03878343105316162,  Val Acc: 0.8999947248404263, Val score: 0.8999947248404263, Time: 0:57:47 *
2021-06-26 15:29:29,652 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 940,  Train Loss: 0.021731365472078323,  Val Acc: 0.9003229847702892, Val score: 0.9003229847702892, Time: 0:58:29 *
2021-06-26 15:30:11,452 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 950,  Train Loss: 0.013475021347403526,  Val Acc: 0.9004888647881599, Val score: 0.9004888647881599, Time: 0:59:11 *
2021-06-26 15:30:53,374 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 960,  Train Loss: 0.014726550318300724,  Val Acc: 0.9006506196812454, Val score: 0.9006506196812454, Time: 0:59:53 *
2021-06-26 15:31:28,380 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 970,  Train Loss: 0.02365615963935852,  Val Acc: 0.900364736033265, Val score: 0.900364736033265, Time: 1:00:28 
2021-06-26 15:32:03,880 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 980,  Train Loss: 0.02406938374042511,  Val Acc: 0.9003324850576729, Val score: 0.9003324850576729, Time: 1:01:03 
2021-06-26 15:32:38,974 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 990,  Train Loss: 0.03232806548476219,  Val Acc: 0.9004714892625503, Val score: 0.9004714892625503, Time: 1:01:38 
2021-06-26 15:33:20,689 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:127] - INFO: Iter: 1000,  Train Loss: 0.02735161781311035,  Val Acc: 0.9008310001377542, Val score: 0.9008310001377542, Time: 1:02:20 *
2021-06-26 15:33:20,695 - /home/users/liuhongli/Models/Bert-Chinese-Text-Classification-Pytorch/train_eval.py[line:130] - INFO: testing 
